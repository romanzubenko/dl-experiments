{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import re\n",
    "import unicodedata\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "\n",
    "class Lang():\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {SOS_TOKEN:'SOS', EOS_TOKEN: 'EOS'}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "            \n",
    "        else:\n",
    "            self.word2count[word] = 1\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go.\\tVa !\\n', 'Run!\\tCours\\u202f!\\n', 'Run!\\tCourez\\u202f!\\n', 'Wow!\\t√áa alors\\u202f!\\n', 'Fire!\\tAu feu !\\n']\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with open('data/eng-fra.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    print(lines[:5])\n",
    "    print(re.match('\\n',lines[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size,hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embed = self.embedding(input).view(1,1,-1)\n",
    "        # let's log it first to see the shape\n",
    "        # need to unroll it with \n",
    "        out, hidden = self.rnn(embed, hidden)\n",
    "\n",
    "        return (out, hidden)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, input_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        embed = self.embedding(input).view(1,1,-1)\n",
    "        \n",
    "        out = F.relu(embed)\n",
    "\n",
    "        # print('DECODER INTERNAL out 1: ', out)\n",
    "\n",
    "        out, hidden = self.rnn(out, hidden)\n",
    "\n",
    "        # print('DECODER INTERNAL out 2: ', out)\n",
    "\n",
    "        out = self.out(out)\n",
    "\n",
    "        # print('DECODER INTERNAL out 3: ', out)\n",
    "        out = self.softmax(out)\n",
    "\n",
    "        # print('DECODER INTERNAL out 4: ', out)\n",
    "\n",
    "        return (out, hidden)\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['tu es plus grand que moi .', 'you re taller than i am .']\n",
      "['tu es en danger .', 'you re in danger .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   6],\n",
      "        [  11],\n",
      "        [ 109],\n",
      "        [ 417],\n",
      "        [   6],\n",
      "        [ 118],\n",
      "        [   3],\n",
      "        [3818],\n",
      "        [   5],\n",
      "        [   1]]), tensor([[   2],\n",
      "        [   3],\n",
      "        [  69],\n",
      "        [1372],\n",
      "        [   2],\n",
      "        [ 618],\n",
      "        [ 129],\n",
      "        [   4],\n",
      "        [   1]]), 'je suis desole si je vous ai embarrassees .', 'i m sorry if i embarrassed you .')\n",
      "(tensor([[528],\n",
      "        [349],\n",
      "        [194],\n",
      "        [529],\n",
      "        [  5],\n",
      "        [  1]]), tensor([[221],\n",
      "        [ 78],\n",
      "        [307],\n",
      "        [  4],\n",
      "        [  1]]), 'ce sont des garcons .', 'they re boys .')\n"
     ]
    }
   ],
   "source": [
    "# ideally we hot encode the dataset, so we don't do it at the time of the training loop\n",
    "dataset = []\n",
    "\n",
    "def sentenceToIndexes(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def sentenceToTensor(lang, sentence):\n",
    "    ind = sentenceToIndexes(lang, sentence)\n",
    "    ind.append(EOS_TOKEN)\n",
    "\n",
    "    return torch.tensor(ind,dtype=torch.long).view(-1, 1)\n",
    "\n",
    "for pair in pairs:\n",
    "    dataset.append((\n",
    "        sentenceToTensor(input_lang,pair[0]),\n",
    "        sentenceToTensor(output_lang,pair[1]),\n",
    "        pair[0],\n",
    "        pair[1]\n",
    "    \n",
    "    ))\n",
    "\n",
    "\n",
    "\n",
    "print(random.choice(dataset))\n",
    "print(random.choice(dataset))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4345"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lang.n_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2803"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index..  100 epoch......  0  loss......  3.237690505981445\n",
      "index..  200 epoch......  0  loss......  2.3552697114944454\n",
      "index..  300 epoch......  0  loss......  2.589359596888225\n",
      "index..  400 epoch......  0  loss......  1.9401830409367884\n",
      "index..  500 epoch......  0  loss......  2.0948022130330397\n",
      "index..  600 epoch......  0  loss......  2.2081492551167803\n",
      "index..  700 epoch......  0  loss......  2.1729643402099605\n",
      "index..  800 epoch......  0  loss......  1.8437348880767828\n",
      "index..  900 epoch......  0  loss......  2.1114242048263545\n",
      "index..  1000 epoch......  0  loss......  2.0603916620072864\n",
      "index..  1100 epoch......  0  loss......  2.002584690343766\n",
      "index..  1200 epoch......  0  loss......  1.816458715756735\n",
      "index..  1300 epoch......  0  loss......  1.894667224679674\n",
      "index..  1400 epoch......  0  loss......  2.4312988329387846\n",
      "index..  1500 epoch......  0  loss......  2.3054464456694466\n",
      "index..  1600 epoch......  0  loss......  1.7915739874839784\n",
      "index..  1700 epoch......  0  loss......  1.8639976919492087\n",
      "index..  1800 epoch......  0  loss......  2.597249987148103\n",
      "index..  1900 epoch......  0  loss......  2.1121633736519594\n",
      "index..  2000 epoch......  0  loss......  2.054660643850054\n",
      "index..  2100 epoch......  0  loss......  1.9847428569793701\n",
      "index..  2200 epoch......  0  loss......  1.833846209843953\n",
      "index..  2300 epoch......  0  loss......  2.0701081868580413\n",
      "index..  2400 epoch......  0  loss......  2.674384977862948\n",
      "index..  2500 epoch......  0  loss......  2.3110298416273927\n",
      "index..  2600 epoch......  0  loss......  1.9664049919446311\n",
      "index..  2700 epoch......  0  loss......  2.0524255817958292\n",
      "index..  2800 epoch......  0  loss......  1.5728447123368579\n",
      "index..  2900 epoch......  0  loss......  1.4430960903579282\n",
      "index..  3000 epoch......  0  loss......  2.881705515021368\n",
      "index..  3100 epoch......  0  loss......  2.177173740114484\n",
      "index..  3200 epoch......  0  loss......  2.3588728869756066\n",
      "index..  3300 epoch......  0  loss......  2.0242913818359365\n",
      "index..  3400 epoch......  0  loss......  1.9420752857072006\n",
      "index..  3500 epoch......  0  loss......  1.1621686726870641\n",
      "index..  3600 epoch......  0  loss......  2.0814288766371702\n",
      "index..  3700 epoch......  0  loss......  2.786379070281983\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/roman/workspace/dl-experiments/translate/translate.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(dataset)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     output, normalized_loss \u001b[39m=\u001b[39m trainSentence(dataset[i][\u001b[39m0\u001b[39;49m], dataset[i][\u001b[39m1\u001b[39;49m], encoder, decoder, encoder_optimizer, decoder_optimizer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m normalized_loss\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39m%\u001b[39m plot_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;32m/Users/roman/workspace/dl-experiments/translate/translate.ipynb Cell 12\u001b[0m in \u001b[0;36mtrainSentence\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39m# print('max',torch.max(output[0]))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m# print('loss:', loss) \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m normalized_loss \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m/\u001b[39m (target_tensor\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m0.0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m encoder_optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roman/workspace/dl-experiments/translate/translate.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m decoder_optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss() \n",
    "hidden_size = 128 \n",
    "learning_rate = 0.001 \n",
    "encoder = Encoder(input_lang.n_words, hidden_size) \n",
    "decoder = Decoder(output_lang.n_words, hidden_size) \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate) \n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate) \n",
    "sample_ouputs = []\n",
    "\n",
    "all_losses = []\n",
    "plot_every = 100\n",
    "total_loss = 0.0\n",
    "\n",
    "\n",
    "def trainSentence(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer): \n",
    "    encoder_optimizer.zero_grad() \n",
    "    decoder_optimizer.zero_grad() \n",
    "    \n",
    "    hidden = encoder.initHidden() \n",
    "    loss = 0.0\n",
    "\n",
    "    for word in input_tensor: \n",
    "        # print('enc word: ', word) \n",
    "        output, hidden = encoder(word, hidden) \n",
    "        # print('enc hidden: ', hidden) \n",
    "        # print('enc output: ', output) \n",
    "    \n",
    "    # print('=============== DONE WITH ENCODING')\n",
    "    output_tensors = [] # Teacher forcing by default, let's do couple of runs and then do non teacher forced \n",
    "    prev_word = torch.tensor([SOS_TOKEN]) \n",
    "    for word in target_tensor: \n",
    "        output, hidden = decoder(prev_word, hidden) \n",
    "\n",
    "        # print('dec hidden: ', hidden) \n",
    "        # print('dec output: ', output) \n",
    "        \n",
    "        prev_word = word \n",
    "        # print('output: ', output[0].size()) \n",
    "        # print('word: ', word) # for each word compute loss ? or just do it in the end # compare word with output \n",
    "        loss += criterion(output[0], word)\n",
    "        output_tensors.append(output[0]) \n",
    "        # print('max',torch.max(output[0]))\n",
    "\n",
    "    # print('loss:', loss) \n",
    "    normalized_loss = loss.item() / (target_tensor.size(0) + 0.0)\n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return (output_tensors, normalized_loss)\n",
    "\n",
    "\n",
    "\n",
    "index = 0\n",
    "for epoch in range(1):\n",
    "    for i in range(0,len(dataset)):\n",
    "        index += 1\n",
    "        output, normalized_loss = trainSentence(dataset[i][0], dataset[i][1], encoder, decoder, encoder_optimizer, decoder_optimizer)\n",
    "        total_loss += normalized_loss\n",
    "        \n",
    "        if index % plot_every == 0:\n",
    "            all_losses.append(total_loss / (plot_every + 0.0))\n",
    "            total_loss = 0\n",
    "            print('index.. ', index, 'epoch...... ', epoch, ' loss...... ',all_losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "m\n",
      "letting\n",
      "to\n",
      ".\n",
      ".\n",
      "EOS\n"
     ]
    }
   ],
   "source": [
    "for b in output:\n",
    "    a = torch.argmax(b)\n",
    "    print(output_lang.index2word[a.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13b1a09d0>]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
